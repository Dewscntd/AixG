"""
ML Pipeline Configuration with Multi-Tier Model Support
Loads configuration for integrated ML service and pipeline stages
"""

import os
import json
import logging
from typing import Dict, Any, Optional
from pathlib import Path
from dataclasses import dataclass, asdict

from .integrated_ml_service import MLServiceConfig
from .model_tier_router import RoutingStrategy

logger = logging.getLogger(__name__)

@dataclass
class PipelineStageConfig:
    """Configuration for individual pipeline stages"""
    enabled: bool = True
    preferred_tier: str = "local"
    confidence_threshold: float = 0.5
    timeout_ms: int = 30000
    max_retries: int = 2
    enable_fallback: bool = True

@dataclass
class MLPipelineConfig:
    """Complete configuration for ML pipeline with multi-tier models"""
    
    # ML Service Configuration
    ml_service: MLServiceConfig = None
    
    # Stage Configurations
    player_detection: PipelineStageConfig = None
    ball_tracking: PipelineStageConfig = None
    action_recognition: PipelineStageConfig = None
    pose_estimation: PipelineStageConfig = None
    
    # Pipeline Settings
    max_concurrent_videos: int = 2
    checkpoint_interval_seconds: int = 30
    enable_gpu_optimization: bool = True
    enable_performance_monitoring: bool = True
    
    # API Keys (can be overridden by environment variables)
    api_keys: Dict[str, str] = None
    
    def __post_init__(self):
        """Initialize default configurations"""
        if self.ml_service is None:
            self.ml_service = MLServiceConfig()
        
        if self.player_detection is None:
            self.player_detection = PipelineStageConfig(\n                preferred_tier="local",\n                confidence_threshold=0.6\n            )\n        \n        if self.ball_tracking is None:\n            self.ball_tracking = PipelineStageConfig(\n                preferred_tier="local",\n                confidence_threshold=0.4\n            )\n        \n        if self.action_recognition is None:\n            self.action_recognition = PipelineStageConfig(\n                preferred_tier="premium",  # More complex task\n                confidence_threshold=0.7\n            )\n        \n        if self.pose_estimation is None:\n            self.pose_estimation = PipelineStageConfig(\n                preferred_tier="local",\n                confidence_threshold=0.6\n            )\n        \n        if self.api_keys is None:\n            self.api_keys = {}\n        \n        # Load API keys from environment variables\n        self._load_api_keys_from_env()\n    \n    def _load_api_keys_from_env(self):\n        """Load API keys from environment variables"""\n        env_keys = {\n            "openai": "OPENAI_API_KEY",\n            "anthropic": "ANTHROPIC_API_KEY", \n            "huggingface": "HUGGINGFACE_API_KEY"\n        }\n        \n        for provider, env_var in env_keys.items():\n            api_key = os.getenv(env_var)\n            if api_key:\n                self.api_keys[provider] = api_key\n                logger.info(f"Loaded API key for {provider} from environment")\n    \n    def to_dict(self) -> Dict[str, Any]:\n        """Convert to dictionary"""\n        return asdict(self)\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'MLPipelineConfig':\n        """Create from dictionary"""\n        # Handle nested configurations\n        if 'ml_service' in data and isinstance(data['ml_service'], dict):\n            ml_service_data = data['ml_service']\n            data['ml_service'] = MLServiceConfig(\n                default_routing_strategy=RoutingStrategy(ml_service_data.get('default_routing_strategy', 'cost_optimized')),\n                enable_gpu_acceleration=ml_service_data.get('enable_gpu_acceleration', True),\n                max_concurrent_requests=ml_service_data.get('max_concurrent_requests', 4),\n                fallback_enabled=ml_service_data.get('fallback_enabled', True),\n                cache_enabled=ml_service_data.get('cache_enabled', True),\n                cost_threshold=ml_service_data.get('cost_threshold', 1.0),\n                api_keys=ml_service_data.get('api_keys', {})\n            )\n        \n        # Handle stage configurations\n        for stage_name in ['player_detection', 'ball_tracking', 'action_recognition', 'pose_estimation']:\n            if stage_name in data and isinstance(data[stage_name], dict):\n                stage_data = data[stage_name]\n                data[stage_name] = PipelineStageConfig(\n                    enabled=stage_data.get('enabled', True),\n                    preferred_tier=stage_data.get('preferred_tier', 'local'),\n                    confidence_threshold=stage_data.get('confidence_threshold', 0.5),\n                    timeout_ms=stage_data.get('timeout_ms', 30000),\n                    max_retries=stage_data.get('max_retries', 2),\n                    enable_fallback=stage_data.get('enable_fallback', True)\n                )\n        \n        return cls(**data)\n\nclass MLPipelineConfigLoader:\n    """Loads and manages ML pipeline configuration"""\n    \n    DEFAULT_CONFIG_PATH = Path("ml_pipeline_config.json")\n    \n    def __init__(self, config_path: Optional[Path] = None):\n        self.config_path = config_path or self.DEFAULT_CONFIG_PATH\n        self._config: Optional[MLPipelineConfig] = None\n    \n    def load(self) -> MLPipelineConfig:\n        """Load configuration from file or create default"""\n        if self.config_path.exists():\n            try:\n                with open(self.config_path, 'r') as f:\n                    config_data = json.load(f)\n                \n                self._config = MLPipelineConfig.from_dict(config_data)\n                logger.info(f"Loaded ML pipeline configuration from {self.config_path}")\n                \n            except Exception as e:\n                logger.error(f"Failed to load configuration from {self.config_path}: {e}")\n                logger.info("Using default configuration")\n                self._config = MLPipelineConfig()\n        else:\n            logger.info(f"Configuration file not found at {self.config_path}, creating default")\n            self._config = MLPipelineConfig()\n            self.save()  # Save default configuration\n        \n        return self._config\n    \n    def save(self, config: Optional[MLPipelineConfig] = None) -> None:\n        """Save configuration to file"""\n        config_to_save = config or self._config\n        if not config_to_save:\n            raise ValueError("No configuration to save")\n        \n        try:\n            # Create directory if it doesn't exist\n            self.config_path.parent.mkdir(parents=True, exist_ok=True)\n            \n            # Convert to dict and save\n            config_dict = config_to_save.to_dict()\n            \n            with open(self.config_path, 'w') as f:\n                json.dump(config_dict, f, indent=2, default=str)\n            \n            logger.info(f"Saved ML pipeline configuration to {self.config_path}")\n            \n        except Exception as e:\n            logger.error(f"Failed to save configuration to {self.config_path}: {e}")\n            raise\n    \n    def get_config(self) -> MLPipelineConfig:\n        """Get current configuration"""\n        if self._config is None:\n            self._config = self.load()\n        return self._config\n    \n    def reload(self) -> MLPipelineConfig:\n        """Reload configuration from file"""\n        self._config = None\n        return self.load()\n    \n    def update_api_key(self, provider: str, api_key: str) -> None:\n        """Update API key for a provider"""\n        config = self.get_config()\n        config.api_keys[provider] = api_key\n        self.save(config)\n        logger.info(f"Updated API key for provider: {provider}")\n    \n    def enable_stage(self, stage_name: str, enabled: bool = True) -> None:\n        """Enable or disable a pipeline stage"""\n        config = self.get_config()\n        stage_config = getattr(config, stage_name, None)\n        if stage_config:\n            stage_config.enabled = enabled\n            self.save(config)\n            logger.info(f"{'Enabled' if enabled else 'Disabled'} stage: {stage_name}")\n        else:\n            raise ValueError(f"Unknown stage: {stage_name}")\n    \n    def set_stage_tier(self, stage_name: str, tier: str) -> None:\n        """Set preferred tier for a stage"""\n        config = self.get_config()\n        stage_config = getattr(config, stage_name, None)\n        if stage_config:\n            stage_config.preferred_tier = tier\n            self.save(config)\n            logger.info(f"Set {stage_name} preferred tier to: {tier}")\n        else:\n            raise ValueError(f"Unknown stage: {stage_name}")\n    \n    def get_stage_config(self, stage_name: str) -> Optional[PipelineStageConfig]:\n        """Get configuration for a specific stage"""\n        config = self.get_config()\n        return getattr(config, stage_name, None)\n    \n    def create_sample_config(self) -> MLPipelineConfig:\n        """Create a sample configuration with all options"""\n        return MLPipelineConfig(\n            ml_service=MLServiceConfig(\n                default_routing_strategy=RoutingStrategy.COST_OPTIMIZED,\n                enable_gpu_acceleration=True,\n                max_concurrent_requests=4,\n                fallback_enabled=True,\n                cache_enabled=True,\n                cost_threshold=1.0\n            ),\n            player_detection=PipelineStageConfig(\n                enabled=True,\n                preferred_tier="local",\n                confidence_threshold=0.6,\n                timeout_ms=30000,\n                max_retries=2,\n                enable_fallback=True\n            ),\n            ball_tracking=PipelineStageConfig(\n                enabled=True,\n                preferred_tier="local", \n                confidence_threshold=0.4,\n                timeout_ms=25000,\n                max_retries=3,\n                enable_fallback=True\n            ),\n            action_recognition=PipelineStageConfig(\n                enabled=True,\n                preferred_tier="premium",\n                confidence_threshold=0.7,\n                timeout_ms=45000,\n                max_retries=2,\n                enable_fallback=True\n            ),\n            pose_estimation=PipelineStageConfig(\n                enabled=True,\n                preferred_tier="local",\n                confidence_threshold=0.6,\n                timeout_ms=35000,\n                max_retries=2,\n                enable_fallback=True\n            ),\n            max_concurrent_videos=2,\n            checkpoint_interval_seconds=30,\n            enable_gpu_optimization=True,\n            enable_performance_monitoring=True,\n            api_keys={\n                # These will be loaded from environment variables\n            }\n        )\n\n# Global configuration loader instance\nconfig_loader = MLPipelineConfigLoader()\n\n# Helper functions\ndef get_ml_pipeline_config() -> MLPipelineConfig:\n    """Get the current ML pipeline configuration"""\n    return config_loader.get_config()\n\ndef setup_ml_service_from_config(config: MLPipelineConfig) -> None:\n    """Setup the global ML service with configuration"""\n    from .integrated_ml_service import ml_service\n    \n    # Update ML service configuration\n    ml_service.config = config.ml_service\n    ml_service._setup_router()\n    \n    # Set API keys\n    if config.api_keys:\n        ml_service.router.set_api_keys(config.api_keys)\n    \n    logger.info("ML service configured successfully")\n\ndef create_stage_from_config(stage_type: str, config: MLPipelineConfig):\n    """Create a pipeline stage from configuration"""\n    stage_config_map = {\n        "player_detection": (config.player_detection, create_enhanced_player_detection_stage),\n        "ball_tracking": (config.ball_tracking, create_enhanced_ball_tracking_stage),\n        "action_recognition": (config.action_recognition, create_enhanced_action_recognition_stage)\n    }\n    \n    if stage_type not in stage_config_map:\n        raise ValueError(f"Unknown stage type: {stage_type}")\n    \n    stage_config, stage_factory = stage_config_map[stage_type]\n    \n    if not stage_config.enabled:\n        return None\n    \n    # Convert stage config to dict for the factory\n    stage_dict = {\n        "preferred_tier": stage_config.preferred_tier,\n        "confidence_threshold": stage_config.confidence_threshold,\n        "timeout_ms": stage_config.timeout_ms,\n        "max_retries": stage_config.max_retries,\n        "enable_fallback": stage_config.enable_fallback\n    }\n    \n    return stage_factory(stage_dict)